{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names & PID\n",
    "\n",
    "- Name: Beverly Peng\n",
    "- PID: A14566574"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can Facebook comments help predict the likelihood of a restaurant receiving food safety violations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Health inspections are vital in the attempt to improve consumer's safety when eating at restaurants. There have been many studies adding information to a pool about how to make the restaurant health inspection process more efficient. There was a study conducted in Philadelphia about how inspection frequency, sociodemographic factors, and food safety violations has on the likelihood of the number of violations chain and nonchain restaurants received (1). They found that chain restaurants had an average of 6.5 total violations per inspection, while nonchains had 9.6. When the number of nonchain inspections increased from 1 to more than 2, there was an average of 1.6 fewer violations; however, this was not seen in chain restaurants. For nonchain restaurants in neighborhoods with a high proportion of black residents, there were lower foodborn-illness risk factor violations but more good retail practice violations per inspection. This data could be used to make the food safety inspection more efficient by focusing more on nonchain restaurants and developing more methods to determine where would benefit the most from these inspections. \n",
    "\n",
    "Social media continues to have a large impact on how we decide which restaurants to eat at. There are websites designed for users to post their reviews and rate the experience on a scale of 1-5. There are restaurants posting on social media advertising themselves and sometimes humoring its audience. Studies centering about using social media as indicators have been risin gin popularity. There is a study from 2013 that found posting restaurant inspection scores online may be a tool for improving food safety (2). Critical violations decreased significantly along with temperature holding violations, hygiene practive violations, and equipment cleanliness violations. Another sudy looked at Yelp reviews and built a predictitive model of restaurants as a way to predict the chance of those restaurants receiving serious health code violations (3). They found a list of positive and negative correlating to the overall restaurant health code rating. There were 3 measurements per keyword: foodborne illness symptoms, physical environment, and positive sentiment. These measurements allowed the algorithm to predict which health violation would be the most likely given the reviews. This model takes into consideration the most useful reviews versus not as useful reviews via an undetermined ranking Yelp algorithm. This study found that the number of stars a restaurant received and five keywords (I love, Affordable, Microwave, Vomit, and Dirty) were able to significantly predict low health code ratings. These keywords were significant in San Francisco, while the New York City model used "recommend" and "I found a". \n",
    "\n",
    "While social media continues to connect us, there is a lot of valuable information about human behavior and connectivity, allowing us to be more efficient with proceedures. \n",
    "\n",
    "References (include links):\n",
    "- 1)\n",
    "Title: Inspection Frequency, Sociodemographic Factors, and Food Safety Violations in Chain and Nonchain Restaurants, Philadelphia, Pennsylvania, 2013-2014\n",
    "Publication Date: 2017 Jan 6\n",
    "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5349477/\n",
    "- 2)\n",
    "Title: Impact of internet posting of restaurant inspection scores on critical violations.\n",
    "Publication Date: 2013 Jun\n",
    "Source: https://www.ncbi.nlm.nih.gov/pubmed/23858661\n",
    "- 3)\n",
    "Title: Supplementing Public Health Inspection via Social Media\n",
    "Publication Date: 2016 Mar 29\n",
    "Source: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4811425/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook comments would be a weak indicator of prediciting food safety violations. This is due to the nature of what a Facebook comment is compared to review websites such as Yelp. Facebook adds another layer of commenting including feedback about the ethics of the restaurant, general support, and store locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea dataset includes comments from restaurant Facebook posts in the San Diego area from 2018-2019 along with the restaurant inspection scores and violations. If possible, a comparision with Yelp would help determine the validity since correlations have already been drawn. \n", 
    "The first reference compares chain and nonchain restaurants, so data from 50 chain and 50 nonchain restaurant Facebook pages would be used. The top 20 comments of 52 randomly selected Facebook posts from 2018 and 2019. This leads to around 100,000 observations. \n", 
    "Yelp has data from the routine health inspections including date of inspection, inspection type, number of violations, type of violation, and overall score (ex. https://www.yelp.com/inspections/starbucks-san-diego-110). Facebook pages are public, so the comments can be seen. Although, I am not sure how to attain this information, but I found a website that could export them to a CSV file. \n", 
    "This data should be stored in a table categorized by restaurant with one column per row. After cleaning the data, each restaurant would have a row with columns indictating the health inspection score, number of violations, chain or nonchain, number of overall positive comments, number of overall negative comments, number of neutral comments. Comment positivity and negativity would be determined by positively and negatively scored key words.  \n", 
    "\n" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data is public. Anyone with a Facebook account can read the comments on restaurant pages. Yelp reviews are also public. The restaurant food safetly results are public as well. The only privacy concerns are connecting the comments to individuals. Removing the name of the commenter will address this concern. There should be no other issue issue with privacy. \n", 
    "\n",
    "There are potential biases in the dataset. Not all restaurants have Facebook pages, but because this would study social media as a predictor, these restaurants would be excluded. There may be bias in which restaurants are selected because more popular and trendy restaurants might have more activity on their page. Due to only 52 posts being choosen, some restaurants would have lower or higher percentage of overall posts being collected. There may be bias in how Facebook ranks comments and how I decide to filter out useful comments. For example, if someone tags someone in the comments and does not have additional words, I would not include that because there would be no indication of the comment being classified as positive or negative. If there were additional words, then that would be classified. This only accounts for populations who comment on Facebook, while a lot of people do not. There could be bias in the way the comments are sorted by popularity. The top comments may not be a good representation of the comments because it could be overly positive or negative. \n",
    "\n",
    "Another issue is the difficulty in associating the date of the post and when the next violation would come. Because the posts and comments are randomly selected, adding time as a factor might make the analysis too complicated. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
